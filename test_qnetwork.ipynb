{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79fc81f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np\n",
    "from helpers import NormalizedEnv, RandomAgent\n",
    "from qnetwork2 import ReplayBuffer, QNetwork\n",
    "from heuristic import HeuristicPendulumAgent\n",
    "from matplotlib import pyplot\n",
    "import torch.optim as optim\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e0dec7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "env = gym.make(\"Pendulum-v1\")\n",
    "norm_env = NormalizedEnv(env) # accept actions between -1 and 1\n",
    "\n",
    "#we fix a torque\n",
    "torque = norm_env.action(norm_env.action_space.sample())\n",
    "agent = HeuristicPendulumAgent(norm_env, torque)\n",
    "\n",
    "buffer = ReplayBuffer(10000)\n",
    "batch_size = 128\n",
    "\n",
    "num_states = env.observation_space.shape[0]\n",
    "num_actions = env.action_space.shape[0]\n",
    "hidden_size = 256 # choose as you wish \n",
    "critic = QNetwork(num_states + num_actions, hidden_size, num_actions, agent)\n",
    "optimizer = optim.Adam(critic.parameters(), lr=1e-4)\n",
    "\n",
    "losses = []\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03fbc883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 0, loss: 75.0203857421875, reward: -8.55 \n",
      "episode: 1, loss: 68.87335968017578, reward: -7.27 \n",
      "episode: 2, loss: 74.60659790039062, reward: -9.28 \n",
      "episode: 3, loss: 78.13536834716797, reward: -9.25 \n",
      "episode: 4, loss: 80.67928314208984, reward: -9.48 \n",
      "episode: 5, loss: 81.85594177246094, reward: -9.11 \n",
      "episode: 6, loss: 81.31925964355469, reward: -8.24 \n",
      "episode: 7, loss: 81.96721649169922, reward: -9.45 \n",
      "episode: 8, loss: 81.24459838867188, reward: -7.27 \n",
      "episode: 9, loss: 80.79081726074219, reward: -8.89 \n",
      "episode: 10, loss: 81.43118286132812, reward: -9.49 \n",
      "episode: 11, loss: 81.864013671875, reward: -9.16 \n",
      "episode: 12, loss: 82.73271179199219, reward: -9.54 \n",
      "episode: 13, loss: 82.35372924804688, reward: -8.3 \n",
      "episode: 14, loss: 82.45398712158203, reward: -9.28 \n",
      "episode: 15, loss: 82.55633544921875, reward: -8.76 \n",
      "episode: 16, loss: 82.84663391113281, reward: -9.54 \n",
      "episode: 17, loss: 83.21505737304688, reward: -8.87 \n",
      "episode: 18, loss: 83.23890686035156, reward: -9.42 \n",
      "episode: 19, loss: 83.74935913085938, reward: -9.44 \n",
      "episode: 20, loss: 84.10132598876953, reward: -9.5 \n",
      "episode: 21, loss: 83.99127197265625, reward: -9.01 \n",
      "episode: 22, loss: 84.1005859375, reward: -8.86 \n",
      "episode: 23, loss: 84.07992553710938, reward: -9.16 \n",
      "episode: 24, loss: 84.2615737915039, reward: -9.5 \n",
      "episode: 25, loss: 84.35769653320312, reward: -9.44 \n",
      "episode: 26, loss: 84.79206848144531, reward: -8.96 \n",
      "episode: 27, loss: 84.44926452636719, reward: -7.68 \n",
      "episode: 28, loss: 83.94367980957031, reward: -8.81 \n",
      "episode: 29, loss: 84.40655517578125, reward: -9.47 \n",
      "episode: 30, loss: 84.43363189697266, reward: -9.14 \n",
      "episode: 31, loss: 84.31253814697266, reward: -9.6 \n",
      "episode: 32, loss: 84.45433807373047, reward: -9.19 \n",
      "episode: 33, loss: 84.61831665039062, reward: -9.27 \n",
      "episode: 34, loss: 84.42041015625, reward: -9.22 \n",
      "episode: 35, loss: 84.72175598144531, reward: -9.32 \n",
      "episode: 36, loss: 84.73123168945312, reward: -8.69 \n",
      "episode: 37, loss: 84.71034240722656, reward: -8.85 \n",
      "episode: 38, loss: 84.61725616455078, reward: -9.28 \n",
      "episode: 39, loss: 84.84564208984375, reward: -9.52 \n",
      "episode: 40, loss: 84.51066589355469, reward: -7.45 \n",
      "episode: 41, loss: 84.51228332519531, reward: -9.31 \n",
      "episode: 42, loss: 84.54609680175781, reward: -7.99 \n",
      "episode: 43, loss: 84.46282958984375, reward: -9.66 \n",
      "episode: 44, loss: 84.28598022460938, reward: -9.37 \n",
      "episode: 45, loss: 84.40469360351562, reward: -9.22 \n",
      "episode: 46, loss: 84.73347473144531, reward: -9.55 \n",
      "episode: 47, loss: 84.80359649658203, reward: -9.39 \n",
      "episode: 48, loss: 84.757080078125, reward: -8.75 \n",
      "episode: 49, loss: 84.78890991210938, reward: -9.23 \n",
      "episode: 50, loss: 85.15705108642578, reward: -9.11 \n",
      "episode: 51, loss: 84.9682388305664, reward: -8.39 \n",
      "episode: 52, loss: 85.64923095703125, reward: -9.53 \n",
      "episode: 53, loss: 85.51403045654297, reward: -9.41 \n",
      "episode: 54, loss: 85.47767639160156, reward: -8.95 \n",
      "episode: 55, loss: 85.16646575927734, reward: -8.5 \n",
      "episode: 56, loss: 85.49898529052734, reward: -9.57 \n",
      "episode: 57, loss: 85.34613037109375, reward: -9.25 \n",
      "episode: 58, loss: 85.4791030883789, reward: -8.77 \n",
      "episode: 59, loss: 85.75080871582031, reward: -8.82 \n",
      "episode: 60, loss: 85.59935760498047, reward: -9.01 \n",
      "episode: 61, loss: 85.63343048095703, reward: -9.21 \n",
      "episode: 62, loss: 85.18167877197266, reward: -7.57 \n",
      "episode: 63, loss: 85.37263488769531, reward: -9.22 \n",
      "episode: 64, loss: 85.20734405517578, reward: -9.18 \n",
      "episode: 65, loss: 85.31707000732422, reward: -8.75 \n",
      "episode: 66, loss: 85.30636596679688, reward: -9.54 \n",
      "episode: 67, loss: 85.38349914550781, reward: -9.26 \n",
      "episode: 68, loss: 85.27680969238281, reward: -9.05 \n",
      "episode: 69, loss: 85.44632720947266, reward: -9.52 \n",
      "episode: 70, loss: 85.25259399414062, reward: -7.84 \n",
      "episode: 71, loss: 85.4067611694336, reward: -9.61 \n",
      "episode: 72, loss: 85.13640594482422, reward: -9.28 \n",
      "episode: 73, loss: 84.85707092285156, reward: -8.9 \n",
      "episode: 74, loss: 84.82546997070312, reward: -9.4 \n",
      "episode: 75, loss: 85.03083038330078, reward: -8.81 \n",
      "episode: 76, loss: 84.75970458984375, reward: -7.93 \n",
      "episode: 77, loss: 85.23764038085938, reward: -8.78 \n",
      "episode: 78, loss: 85.09989166259766, reward: -9.44 \n",
      "episode: 79, loss: 85.28153228759766, reward: -9.58 \n",
      "episode: 80, loss: 85.5962142944336, reward: -9.43 \n",
      "episode: 81, loss: 85.34693145751953, reward: -9.25 \n",
      "episode: 82, loss: 85.38224792480469, reward: -9.54 \n",
      "episode: 83, loss: 85.27909088134766, reward: -8.27 \n",
      "episode: 84, loss: 85.39972686767578, reward: -9.5 \n",
      "episode: 85, loss: 85.24686431884766, reward: -9.33 \n",
      "episode: 86, loss: 85.46570587158203, reward: -9.49 \n",
      "episode: 87, loss: 85.17948150634766, reward: -8.0 \n",
      "episode: 88, loss: 85.09292602539062, reward: -9.17 \n",
      "episode: 89, loss: 84.77688598632812, reward: -9.55 \n",
      "episode: 90, loss: 85.43649291992188, reward: -9.53 \n",
      "episode: 91, loss: 85.29385375976562, reward: -9.35 \n",
      "episode: 92, loss: 86.2344741821289, reward: -9.58 \n",
      "episode: 93, loss: 85.87562561035156, reward: -9.16 \n",
      "episode: 94, loss: 85.56207275390625, reward: -8.94 \n",
      "episode: 95, loss: 85.31432342529297, reward: -7.53 \n",
      "episode: 96, loss: 85.17969512939453, reward: -9.61 \n",
      "episode: 97, loss: 85.01506805419922, reward: -8.57 \n",
      "episode: 98, loss: 85.19470977783203, reward: -7.83 \n",
      "episode: 99, loss: 84.8044204711914, reward: -9.15 \n",
      "episode: 100, loss: 85.01029968261719, reward: -9.71 \n",
      "episode: 101, loss: 85.21729278564453, reward: -8.78 \n",
      "episode: 102, loss: 85.00347900390625, reward: -9.15 \n",
      "episode: 103, loss: 84.85209655761719, reward: -9.09 \n",
      "episode: 104, loss: 84.96206665039062, reward: -8.8 \n",
      "episode: 105, loss: 84.75230407714844, reward: -7.69 \n",
      "episode: 106, loss: 84.79498291015625, reward: -9.2 \n",
      "episode: 107, loss: 84.56253814697266, reward: -9.05 \n",
      "episode: 108, loss: 84.67570495605469, reward: -8.71 \n",
      "episode: 109, loss: 84.6337661743164, reward: -9.12 \n",
      "episode: 110, loss: 84.976806640625, reward: -8.16 \n",
      "episode: 111, loss: 84.35020446777344, reward: -9.31 \n",
      "episode: 112, loss: 84.6864242553711, reward: -9.14 \n",
      "episode: 113, loss: 84.65736389160156, reward: -9.52 \n",
      "episode: 114, loss: 84.84898376464844, reward: -8.94 \n",
      "episode: 115, loss: 84.47476196289062, reward: -7.0 \n",
      "episode: 116, loss: 84.52008819580078, reward: -7.92 \n",
      "episode: 117, loss: 84.11847686767578, reward: -9.14 \n",
      "episode: 118, loss: 84.36001586914062, reward: -9.4 \n",
      "episode: 119, loss: 84.1617660522461, reward: -9.42 \n",
      "episode: 120, loss: 84.5443344116211, reward: -9.67 \n",
      "episode: 121, loss: 84.49260711669922, reward: -9.51 \n",
      "episode: 122, loss: 84.69366455078125, reward: -9.52 \n",
      "episode: 123, loss: 84.72224426269531, reward: -9.35 \n",
      "episode: 124, loss: 84.78577423095703, reward: -8.06 \n",
      "episode: 125, loss: 84.72406005859375, reward: -9.5 \n",
      "episode: 126, loss: 84.75370788574219, reward: -9.26 \n",
      "episode: 127, loss: 85.03662872314453, reward: -9.26 \n",
      "episode: 128, loss: 85.14369201660156, reward: -9.22 \n",
      "episode: 129, loss: 85.0930404663086, reward: -9.47 \n",
      "episode: 130, loss: 84.9524917602539, reward: -9.35 \n",
      "episode: 131, loss: 84.96757507324219, reward: -8.86 \n",
      "episode: 132, loss: 84.78849792480469, reward: -8.82 \n",
      "episode: 133, loss: 84.98104858398438, reward: -9.52 \n",
      "episode: 134, loss: 84.9694595336914, reward: -9.39 \n",
      "episode: 135, loss: 84.93387603759766, reward: -9.2 \n",
      "episode: 136, loss: 84.72693634033203, reward: -8.01 \n",
      "episode: 137, loss: 84.68997955322266, reward: -7.88 \n",
      "episode: 138, loss: 84.58810424804688, reward: -9.27 \n",
      "episode: 139, loss: 84.52230834960938, reward: -8.63 \n",
      "episode: 140, loss: 84.23017883300781, reward: -8.79 \n",
      "episode: 141, loss: 83.98030090332031, reward: -7.59 \n",
      "episode: 142, loss: 83.595458984375, reward: -9.16 \n",
      "episode: 143, loss: 83.60343933105469, reward: -7.88 \n",
      "episode: 144, loss: 83.16999053955078, reward: -8.61 \n",
      "episode: 145, loss: 83.65644836425781, reward: -8.72 \n",
      "episode: 146, loss: 83.33586120605469, reward: -9.44 \n",
      "episode: 147, loss: 83.61264038085938, reward: -9.37 \n",
      "episode: 148, loss: 83.65531158447266, reward: -7.73 \n",
      "episode: 149, loss: 83.47753143310547, reward: -9.11 \n",
      "episode: 150, loss: 83.5739974975586, reward: -9.25 \n",
      "episode: 151, loss: 83.2555923461914, reward: -7.99 \n",
      "episode: 152, loss: 83.52873992919922, reward: -9.31 \n",
      "episode: 153, loss: 83.21293640136719, reward: -8.93 \n",
      "episode: 154, loss: 83.6988296508789, reward: -9.35 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 155, loss: 83.85814666748047, reward: -9.12 \n",
      "episode: 156, loss: 83.75861358642578, reward: -8.52 \n",
      "episode: 157, loss: 83.56068420410156, reward: -8.51 \n",
      "episode: 158, loss: 83.5046615600586, reward: -7.6 \n",
      "episode: 159, loss: 83.31734466552734, reward: -9.11 \n",
      "episode: 160, loss: 83.71080780029297, reward: -9.54 \n",
      "episode: 161, loss: 83.98175811767578, reward: -9.69 \n",
      "episode: 162, loss: 83.78915405273438, reward: -9.2 \n",
      "episode: 163, loss: 83.92861938476562, reward: -9.23 \n",
      "episode: 164, loss: 83.86967468261719, reward: -9.48 \n",
      "episode: 165, loss: 83.87960815429688, reward: -8.77 \n",
      "episode: 166, loss: 84.04359436035156, reward: -8.75 \n",
      "episode: 167, loss: 84.48729705810547, reward: -9.17 \n",
      "episode: 168, loss: 84.17633056640625, reward: -9.52 \n",
      "episode: 169, loss: 84.10124969482422, reward: -9.12 \n",
      "episode: 170, loss: 84.10431671142578, reward: -9.2 \n",
      "episode: 171, loss: 83.94111633300781, reward: -9.05 \n",
      "episode: 172, loss: 84.00111389160156, reward: -9.37 \n",
      "episode: 173, loss: 84.10906219482422, reward: -9.39 \n",
      "episode: 174, loss: 84.49015808105469, reward: -9.31 \n",
      "episode: 175, loss: 84.11810302734375, reward: -9.47 \n",
      "episode: 176, loss: 84.21871948242188, reward: -9.71 \n",
      "episode: 177, loss: 84.22103881835938, reward: -9.06 \n",
      "episode: 178, loss: 84.17761993408203, reward: -8.49 \n",
      "episode: 179, loss: 83.73883819580078, reward: -7.55 \n",
      "episode: 180, loss: 83.62450408935547, reward: -7.48 \n",
      "episode: 181, loss: 83.28530883789062, reward: -8.84 \n",
      "episode: 182, loss: 83.33073425292969, reward: -8.64 \n",
      "episode: 183, loss: 83.43338012695312, reward: -9.71 \n",
      "episode: 184, loss: 83.46599578857422, reward: -9.48 \n",
      "episode: 185, loss: 83.30740356445312, reward: -9.56 \n",
      "episode: 186, loss: 83.07079315185547, reward: -6.17 \n",
      "episode: 187, loss: 83.31420135498047, reward: -9.55 \n",
      "episode: 188, loss: 83.17565155029297, reward: -8.73 \n",
      "episode: 189, loss: 83.788330078125, reward: -9.67 \n",
      "episode: 190, loss: 83.59246063232422, reward: -8.78 \n",
      "episode: 191, loss: 84.04332733154297, reward: -9.62 \n",
      "episode: 192, loss: 84.39010620117188, reward: -9.55 \n",
      "episode: 193, loss: 84.09214782714844, reward: -6.28 \n",
      "episode: 194, loss: 84.20236206054688, reward: -9.29 \n",
      "episode: 195, loss: 84.36384582519531, reward: -9.5 \n",
      "episode: 196, loss: 83.92034912109375, reward: -8.17 \n",
      "episode: 197, loss: 83.88861083984375, reward: -9.21 \n",
      "episode: 198, loss: 83.93011474609375, reward: -7.85 \n",
      "episode: 199, loss: 84.07929992675781, reward: -9.6 \n",
      "episode: 200, loss: 84.24683380126953, reward: -9.49 \n",
      "episode: 201, loss: 84.1099624633789, reward: -9.39 \n",
      "episode: 202, loss: 84.32733154296875, reward: -9.63 \n",
      "episode: 203, loss: 84.59112548828125, reward: -9.53 \n",
      "episode: 204, loss: 84.790283203125, reward: -8.3 \n",
      "episode: 205, loss: 84.24271392822266, reward: -8.74 \n",
      "episode: 206, loss: 84.40653228759766, reward: -9.43 \n",
      "episode: 207, loss: 84.53500366210938, reward: -9.12 \n",
      "episode: 208, loss: 85.06246185302734, reward: -9.35 \n",
      "episode: 209, loss: 85.15937805175781, reward: -9.62 \n",
      "episode: 210, loss: 85.16741943359375, reward: -9.23 \n",
      "episode: 211, loss: 85.11278533935547, reward: -9.55 \n",
      "episode: 212, loss: 85.05046844482422, reward: -7.8 \n",
      "episode: 213, loss: 84.59935760498047, reward: -7.88 \n",
      "episode: 214, loss: 84.33622741699219, reward: -7.92 \n",
      "episode: 215, loss: 84.25017547607422, reward: -8.86 \n",
      "episode: 216, loss: 84.04086303710938, reward: -8.04 \n",
      "episode: 217, loss: 83.93217468261719, reward: -9.47 \n",
      "episode: 218, loss: 84.19363403320312, reward: -9.03 \n",
      "episode: 219, loss: 84.04773712158203, reward: -8.9 \n",
      "episode: 220, loss: 84.21478271484375, reward: -9.58 \n",
      "episode: 221, loss: 83.94733428955078, reward: -9.4 \n",
      "episode: 222, loss: 84.15699005126953, reward: -8.83 \n",
      "episode: 223, loss: 84.08663177490234, reward: -9.52 \n",
      "episode: 224, loss: 84.09465026855469, reward: -9.58 \n",
      "episode: 225, loss: 84.09901428222656, reward: -9.49 \n",
      "episode: 226, loss: 84.1023941040039, reward: -9.48 \n",
      "episode: 227, loss: 84.10558319091797, reward: -9.44 \n",
      "episode: 228, loss: 84.18844604492188, reward: -9.53 \n",
      "episode: 229, loss: 84.44763946533203, reward: -8.77 \n",
      "episode: 230, loss: 85.0418930053711, reward: -9.14 \n",
      "episode: 231, loss: 84.80008697509766, reward: -9.51 \n",
      "episode: 232, loss: 85.29251861572266, reward: -9.22 \n",
      "episode: 233, loss: 84.9779281616211, reward: -9.21 \n",
      "episode: 234, loss: 84.83390808105469, reward: -9.22 \n",
      "episode: 235, loss: 84.80671691894531, reward: -8.78 \n",
      "episode: 236, loss: 85.19947052001953, reward: -9.52 \n",
      "episode: 237, loss: 85.55291748046875, reward: -9.43 \n",
      "episode: 238, loss: 85.58462524414062, reward: -9.45 \n",
      "episode: 239, loss: 85.74083709716797, reward: -9.6 \n",
      "episode: 240, loss: 85.81954193115234, reward: -9.39 \n",
      "episode: 241, loss: 85.7040023803711, reward: -9.61 \n",
      "episode: 242, loss: 85.70166015625, reward: -9.32 \n",
      "episode: 243, loss: 86.29871368408203, reward: -9.69 \n",
      "episode: 244, loss: 86.77371215820312, reward: -9.61 \n",
      "episode: 245, loss: 86.71009063720703, reward: -9.75 \n",
      "episode: 246, loss: 86.90308380126953, reward: -9.41 \n",
      "episode: 247, loss: 86.9260482788086, reward: -9.53 \n",
      "episode: 248, loss: 87.0060806274414, reward: -8.75 \n",
      "episode: 249, loss: 87.13583374023438, reward: -8.78 \n",
      "episode: 250, loss: 87.03787994384766, reward: -9.63 \n",
      "episode: 251, loss: 87.00021362304688, reward: -9.54 \n",
      "episode: 252, loss: 87.11923217773438, reward: -9.31 \n",
      "episode: 253, loss: 86.9129409790039, reward: -9.24 \n",
      "episode: 254, loss: 87.02545166015625, reward: -9.44 \n",
      "episode: 255, loss: 87.09994506835938, reward: -9.4 \n",
      "episode: 256, loss: 87.5073013305664, reward: -9.69 \n",
      "episode: 257, loss: 87.59904479980469, reward: -8.94 \n",
      "episode: 258, loss: 87.13008880615234, reward: -8.41 \n",
      "episode: 259, loss: 87.10078430175781, reward: -9.09 \n",
      "episode: 260, loss: 86.79753875732422, reward: -7.99 \n",
      "episode: 261, loss: 86.4599609375, reward: -8.84 \n",
      "episode: 262, loss: 86.7773666381836, reward: -9.55 \n",
      "episode: 263, loss: 87.38909912109375, reward: -9.41 \n",
      "episode: 264, loss: 87.60469055175781, reward: -9.3 \n",
      "episode: 265, loss: 87.74652099609375, reward: -9.22 \n",
      "episode: 266, loss: 87.93391418457031, reward: -9.28 \n",
      "episode: 267, loss: 87.89945220947266, reward: -9.64 \n",
      "episode: 268, loss: 88.14878845214844, reward: -9.52 \n",
      "episode: 269, loss: 88.34374237060547, reward: -9.6 \n",
      "episode: 270, loss: 88.18395233154297, reward: -8.38 \n",
      "episode: 271, loss: 88.00745391845703, reward: -9.08 \n",
      "episode: 272, loss: 88.09654235839844, reward: -9.17 \n",
      "episode: 273, loss: 88.10859680175781, reward: -9.54 \n",
      "episode: 274, loss: 87.98158264160156, reward: -9.52 \n",
      "episode: 275, loss: 88.21234130859375, reward: -9.67 \n",
      "episode: 276, loss: 88.29383087158203, reward: -9.57 \n",
      "episode: 277, loss: 87.9543228149414, reward: -8.47 \n",
      "episode: 278, loss: 87.70988464355469, reward: -6.53 \n",
      "episode: 279, loss: 87.36581420898438, reward: -8.95 \n",
      "episode: 280, loss: 87.62384033203125, reward: -9.28 \n",
      "episode: 281, loss: 87.24658203125, reward: -9.28 \n",
      "episode: 282, loss: 87.37853240966797, reward: -9.29 \n",
      "episode: 283, loss: 87.33140563964844, reward: -8.74 \n",
      "episode: 284, loss: 87.18363952636719, reward: -9.44 \n",
      "episode: 285, loss: 87.50135040283203, reward: -9.5 \n",
      "episode: 286, loss: 87.59693145751953, reward: -9.11 \n",
      "episode: 287, loss: 87.28882598876953, reward: -9.33 \n",
      "episode: 288, loss: 87.28599548339844, reward: -9.22 \n",
      "episode: 289, loss: 87.39795684814453, reward: -9.23 \n",
      "episode: 290, loss: 87.06158447265625, reward: -8.7 \n",
      "episode: 291, loss: 86.45597839355469, reward: -9.19 \n",
      "episode: 292, loss: 86.94855499267578, reward: -9.44 \n",
      "episode: 293, loss: 87.20130157470703, reward: -9.78 \n",
      "episode: 294, loss: 87.0981674194336, reward: -9.61 \n",
      "episode: 295, loss: 86.82185363769531, reward: -7.61 \n",
      "episode: 296, loss: 86.41722869873047, reward: -9.16 \n",
      "episode: 297, loss: 86.02572631835938, reward: -8.7 \n",
      "episode: 298, loss: 85.99549102783203, reward: -8.98 \n",
      "episode: 299, loss: 86.4644546508789, reward: -8.76 \n",
      "episode: 300, loss: 86.1007308959961, reward: -9.06 \n",
      "episode: 301, loss: 85.70567321777344, reward: -7.87 \n",
      "episode: 302, loss: 85.43632507324219, reward: -8.13 \n",
      "episode: 303, loss: 85.31423950195312, reward: -8.64 \n",
      "episode: 304, loss: 85.1126937866211, reward: -9.32 \n",
      "episode: 305, loss: 85.16661834716797, reward: -9.44 \n",
      "episode: 306, loss: 85.30705261230469, reward: -9.47 \n",
      "episode: 307, loss: 85.30810546875, reward: -9.44 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 308, loss: 85.27156066894531, reward: -8.56 \n",
      "episode: 309, loss: 85.27562713623047, reward: -7.8 \n",
      "episode: 310, loss: 85.2242202758789, reward: -9.55 \n",
      "episode: 311, loss: 85.6860122680664, reward: -9.2 \n",
      "episode: 312, loss: 85.1669921875, reward: -9.45 \n",
      "episode: 313, loss: 85.32478332519531, reward: -9.47 \n",
      "episode: 314, loss: 85.07171630859375, reward: -5.66 \n",
      "episode: 315, loss: 84.98896789550781, reward: -9.42 \n",
      "episode: 316, loss: 84.93144226074219, reward: -9.58 \n",
      "episode: 317, loss: 84.91027069091797, reward: -8.8 \n",
      "episode: 318, loss: 84.3067398071289, reward: -9.58 \n",
      "episode: 319, loss: 84.51884460449219, reward: -8.86 \n",
      "episode: 320, loss: 84.6871566772461, reward: -9.54 \n",
      "episode: 321, loss: 84.79401397705078, reward: -9.35 \n",
      "episode: 322, loss: 85.03912353515625, reward: -9.09 \n",
      "episode: 323, loss: 84.56763458251953, reward: -7.62 \n",
      "episode: 324, loss: 84.3705825805664, reward: -9.53 \n",
      "episode: 325, loss: 84.57240295410156, reward: -9.59 \n",
      "episode: 326, loss: 84.3978500366211, reward: -9.63 \n",
      "episode: 327, loss: 84.1133041381836, reward: -8.56 \n",
      "episode: 328, loss: 84.9537124633789, reward: -9.45 \n",
      "episode: 329, loss: 85.16173553466797, reward: -9.15 \n",
      "episode: 330, loss: 84.8285903930664, reward: -8.91 \n",
      "episode: 331, loss: 84.39310455322266, reward: -7.35 \n",
      "episode: 332, loss: 84.40371704101562, reward: -9.58 \n",
      "episode: 333, loss: 84.73159790039062, reward: -9.15 \n",
      "episode: 334, loss: 84.64197540283203, reward: -9.3 \n",
      "episode: 335, loss: 85.0464859008789, reward: -9.72 \n",
      "episode: 336, loss: 84.68289947509766, reward: -9.12 \n",
      "episode: 337, loss: 84.62251281738281, reward: -8.57 \n",
      "episode: 338, loss: 84.70789337158203, reward: -9.27 \n",
      "episode: 339, loss: 84.71821594238281, reward: -9.44 \n",
      "episode: 340, loss: 84.96272277832031, reward: -9.43 \n",
      "episode: 341, loss: 84.85320281982422, reward: -8.87 \n",
      "episode: 342, loss: 84.72357177734375, reward: -7.93 \n",
      "episode: 343, loss: 84.62663269042969, reward: -9.58 \n",
      "episode: 344, loss: 84.55291748046875, reward: -9.33 \n",
      "episode: 345, loss: 84.72046661376953, reward: -9.49 \n",
      "episode: 346, loss: 84.6379623413086, reward: -9.07 \n",
      "episode: 347, loss: 84.8598861694336, reward: -9.1 \n",
      "episode: 348, loss: 85.1841049194336, reward: -9.15 \n",
      "episode: 349, loss: 84.89470672607422, reward: -9.47 \n",
      "episode: 350, loss: 85.1216812133789, reward: -8.96 \n",
      "episode: 351, loss: 85.06839752197266, reward: -9.25 \n",
      "episode: 352, loss: 85.31787109375, reward: -8.76 \n",
      "episode: 353, loss: 85.29216766357422, reward: -8.1 \n",
      "episode: 354, loss: 85.28839874267578, reward: -7.69 \n",
      "episode: 355, loss: 84.7728500366211, reward: -9.02 \n",
      "episode: 356, loss: 84.64888763427734, reward: -8.86 \n",
      "episode: 357, loss: 84.68383026123047, reward: -8.68 \n",
      "episode: 358, loss: 84.24386596679688, reward: -8.39 \n",
      "episode: 359, loss: 84.58236694335938, reward: -8.8 \n",
      "episode: 360, loss: 84.76541137695312, reward: -9.22 \n",
      "episode: 361, loss: 84.2394790649414, reward: -7.52 \n",
      "episode: 362, loss: 84.06452941894531, reward: -9.35 \n",
      "episode: 363, loss: 84.54714965820312, reward: -9.65 \n",
      "episode: 364, loss: 85.12615966796875, reward: -9.11 \n",
      "episode: 365, loss: 85.03668212890625, reward: -9.45 \n",
      "episode: 366, loss: 85.37960815429688, reward: -9.55 \n",
      "episode: 367, loss: 84.40034484863281, reward: -6.59 \n",
      "episode: 368, loss: 84.62911224365234, reward: -9.19 \n",
      "episode: 369, loss: 84.82662200927734, reward: -9.35 \n",
      "episode: 370, loss: 84.6758041381836, reward: -9.56 \n",
      "episode: 371, loss: 84.3354263305664, reward: -8.33 \n",
      "episode: 372, loss: 84.4585952758789, reward: -9.15 \n",
      "episode: 373, loss: 84.79390716552734, reward: -8.88 \n",
      "episode: 374, loss: 84.66204071044922, reward: -9.58 \n",
      "episode: 375, loss: 84.61105346679688, reward: -9.26 \n",
      "episode: 376, loss: 84.22161102294922, reward: -8.32 \n",
      "episode: 377, loss: 84.30805969238281, reward: -9.17 \n",
      "episode: 378, loss: 84.43251037597656, reward: -9.55 \n",
      "episode: 379, loss: 84.63591766357422, reward: -9.82 \n",
      "episode: 380, loss: 84.41249084472656, reward: -9.25 \n",
      "episode: 381, loss: 85.09851837158203, reward: -8.72 \n",
      "episode: 382, loss: 84.8547592163086, reward: -8.89 \n",
      "episode: 383, loss: 84.5517578125, reward: -9.58 \n",
      "episode: 384, loss: 85.01313781738281, reward: -9.3 \n",
      "episode: 385, loss: 84.79332733154297, reward: -9.48 \n",
      "episode: 386, loss: 84.56967163085938, reward: -7.94 \n",
      "episode: 387, loss: 84.6771011352539, reward: -8.83 \n",
      "episode: 388, loss: 84.81769561767578, reward: -8.52 \n",
      "episode: 389, loss: 84.08726501464844, reward: -7.41 \n",
      "episode: 390, loss: 83.8075180053711, reward: -9.15 \n",
      "episode: 391, loss: 83.9809341430664, reward: -9.43 \n",
      "episode: 392, loss: 83.93498229980469, reward: -9.36 \n",
      "episode: 393, loss: 84.23980712890625, reward: -9.38 \n",
      "episode: 394, loss: 84.28472900390625, reward: -8.79 \n",
      "episode: 395, loss: 84.05229187011719, reward: -8.78 \n",
      "episode: 396, loss: 83.76265716552734, reward: -9.07 \n",
      "episode: 397, loss: 84.01949310302734, reward: -9.58 \n",
      "episode: 398, loss: 84.2030258178711, reward: -9.26 \n",
      "episode: 399, loss: 84.03082275390625, reward: -7.69 \n",
      "episode: 400, loss: 83.89427947998047, reward: -9.46 \n",
      "episode: 401, loss: 84.0210952758789, reward: -9.37 \n",
      "episode: 402, loss: 83.93126678466797, reward: -9.44 \n",
      "episode: 403, loss: 84.35464477539062, reward: -9.46 \n",
      "episode: 404, loss: 84.46743774414062, reward: -9.15 \n",
      "episode: 405, loss: 84.88968658447266, reward: -9.22 \n",
      "episode: 406, loss: 84.92786407470703, reward: -9.53 \n",
      "episode: 407, loss: 85.38713836669922, reward: -9.75 \n",
      "episode: 408, loss: 85.49462890625, reward: -9.49 \n",
      "episode: 409, loss: 85.26726531982422, reward: -9.23 \n",
      "episode: 410, loss: 85.40339660644531, reward: -9.3 \n",
      "episode: 411, loss: 85.880126953125, reward: -9.17 \n",
      "episode: 412, loss: 86.10791015625, reward: -9.58 \n",
      "episode: 413, loss: 86.11408233642578, reward: -9.65 \n",
      "episode: 414, loss: 86.1323013305664, reward: -9.25 \n",
      "episode: 415, loss: 85.84188842773438, reward: -9.13 \n",
      "episode: 416, loss: 85.94097900390625, reward: -9.54 \n",
      "episode: 417, loss: 86.40977478027344, reward: -9.53 \n",
      "episode: 418, loss: 86.67064666748047, reward: -9.27 \n",
      "episode: 419, loss: 86.8000717163086, reward: -8.75 \n",
      "episode: 420, loss: 86.47631072998047, reward: -9.53 \n",
      "episode: 421, loss: 86.5059585571289, reward: -9.3 \n",
      "episode: 422, loss: 86.578125, reward: -8.29 \n",
      "episode: 423, loss: 86.331787109375, reward: -8.8 \n",
      "episode: 424, loss: 86.48970794677734, reward: -9.29 \n",
      "episode: 425, loss: 86.3497085571289, reward: -9.45 \n",
      "episode: 426, loss: 86.8030776977539, reward: -9.51 \n",
      "episode: 427, loss: 87.04447174072266, reward: -9.75 \n",
      "episode: 428, loss: 86.59208679199219, reward: -8.76 \n",
      "episode: 429, loss: 86.67627716064453, reward: -9.56 \n",
      "episode: 430, loss: 86.54450988769531, reward: -9.07 \n",
      "episode: 431, loss: 86.5958480834961, reward: -8.65 \n",
      "episode: 432, loss: 86.7457504272461, reward: -9.23 \n",
      "episode: 433, loss: 86.10038757324219, reward: -6.73 \n",
      "episode: 434, loss: 86.21357727050781, reward: -9.48 \n",
      "episode: 435, loss: 85.9959487915039, reward: -9.11 \n",
      "episode: 436, loss: 86.06062316894531, reward: -8.01 \n",
      "episode: 437, loss: 86.09574127197266, reward: -9.62 \n",
      "episode: 438, loss: 86.21794891357422, reward: -9.0 \n",
      "episode: 439, loss: 86.62857055664062, reward: -8.86 \n",
      "episode: 440, loss: 86.45177459716797, reward: -8.55 \n",
      "episode: 441, loss: 86.30036926269531, reward: -9.3 \n",
      "episode: 442, loss: 86.09689331054688, reward: -9.31 \n",
      "episode: 443, loss: 86.3610610961914, reward: -9.13 \n",
      "episode: 444, loss: 86.11695098876953, reward: -8.78 \n",
      "episode: 445, loss: 86.42609405517578, reward: -9.2 \n",
      "episode: 446, loss: 86.17550659179688, reward: -4.87 \n",
      "episode: 447, loss: 85.54029083251953, reward: -9.62 \n",
      "episode: 448, loss: 85.40328216552734, reward: -9.31 \n",
      "episode: 449, loss: 85.6836929321289, reward: -9.35 \n",
      "episode: 450, loss: 85.8683853149414, reward: -9.59 \n",
      "episode: 451, loss: 85.90512084960938, reward: -8.79 \n",
      "episode: 452, loss: 85.81414031982422, reward: -9.49 \n",
      "episode: 453, loss: 85.89027404785156, reward: -9.36 \n",
      "episode: 454, loss: 85.83349609375, reward: -8.62 \n",
      "episode: 455, loss: 85.87967681884766, reward: -9.49 \n",
      "episode: 456, loss: 85.41607666015625, reward: -8.02 \n",
      "episode: 457, loss: 85.25177001953125, reward: -9.16 \n",
      "episode: 458, loss: 85.265625, reward: -9.59 \n",
      "episode: 459, loss: 85.18534851074219, reward: -8.6 \n",
      "episode: 460, loss: 84.87767791748047, reward: -9.49 \n",
      "episode: 461, loss: 84.98527526855469, reward: -8.43 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 462, loss: 85.34992218017578, reward: -9.47 \n",
      "episode: 463, loss: 84.95396423339844, reward: -9.65 \n",
      "episode: 464, loss: 84.98279571533203, reward: -9.63 \n",
      "episode: 465, loss: 85.27625274658203, reward: -9.37 \n",
      "episode: 466, loss: 85.15985107421875, reward: -6.7 \n",
      "episode: 467, loss: 84.31146240234375, reward: -8.76 \n",
      "episode: 468, loss: 84.48445129394531, reward: -9.19 \n",
      "episode: 469, loss: 84.57073974609375, reward: -9.54 \n",
      "episode: 470, loss: 84.48916625976562, reward: -9.34 \n",
      "episode: 471, loss: 84.42183685302734, reward: -9.43 \n",
      "episode: 472, loss: 84.53400421142578, reward: -8.43 \n",
      "episode: 473, loss: 84.50640869140625, reward: -9.15 \n",
      "episode: 474, loss: 84.54721069335938, reward: -9.41 \n",
      "episode: 475, loss: 84.08087921142578, reward: -6.83 \n",
      "episode: 476, loss: 83.95381164550781, reward: -8.5 \n",
      "episode: 477, loss: 83.70121765136719, reward: -9.71 \n",
      "episode: 478, loss: 83.62022399902344, reward: -9.11 \n",
      "episode: 479, loss: 83.89620208740234, reward: -9.24 \n",
      "episode: 480, loss: 83.81873321533203, reward: -9.48 \n",
      "episode: 481, loss: 83.85498809814453, reward: -9.48 \n",
      "episode: 482, loss: 84.1707992553711, reward: -9.69 \n",
      "episode: 483, loss: 84.5711898803711, reward: -9.27 \n",
      "episode: 484, loss: 84.87113189697266, reward: -9.26 \n",
      "episode: 485, loss: 84.67474365234375, reward: -8.88 \n",
      "episode: 486, loss: 84.75220489501953, reward: -9.2 \n",
      "episode: 487, loss: 84.63026428222656, reward: -8.76 \n",
      "episode: 488, loss: 84.78132629394531, reward: -9.35 \n",
      "episode: 489, loss: 84.8967056274414, reward: -8.56 \n",
      "episode: 490, loss: 84.77804565429688, reward: -8.79 \n",
      "episode: 491, loss: 84.91461181640625, reward: -9.18 \n",
      "episode: 492, loss: 84.89038848876953, reward: -9.38 \n",
      "episode: 493, loss: 84.5721206665039, reward: -7.93 \n",
      "episode: 494, loss: 84.4173812866211, reward: -8.82 \n",
      "episode: 495, loss: 84.35509490966797, reward: -8.81 \n",
      "episode: 496, loss: 84.71038818359375, reward: -7.27 \n",
      "episode: 497, loss: 84.88189697265625, reward: -8.97 \n",
      "episode: 498, loss: 84.6515121459961, reward: -9.58 \n",
      "episode: 499, loss: 84.28487396240234, reward: -8.75 \n"
     ]
    }
   ],
   "source": [
    "for episode in range(500): \n",
    "    state, info = norm_env.reset()\n",
    "    trunc = False\n",
    "    \n",
    "    episode_loss = []\n",
    "    av_episode_loss = 0\n",
    "    \n",
    "    episode_reward = []\n",
    "    av_episode_reward = 0\n",
    "    \n",
    "    while not trunc:\n",
    "        action = agent.compute_action(state)\n",
    "        # print(norm_env.step(action))\n",
    "        next_state, reward, terminated, trunc, info = norm_env.step(action)\n",
    "        buffer.add(state, action, reward, next_state, trunc)\n",
    "        \n",
    "        if len(buffer) > batch_size:\n",
    "            transition = buffer.sample(batch_size)\n",
    "            loss = critic.update(transition, trunc, 0.99)\n",
    "            optimizer.zero_grad()\n",
    "            optimizer.step()\n",
    "            episode_loss.append(loss)\n",
    "        \n",
    "        state = next_state\n",
    "        episode_reward.append(reward)\n",
    "        \n",
    "        if trunc:\n",
    "            av_episode_loss = np.mean(episode_loss)\n",
    "            av_episode_reward = np.mean(episode_reward)\n",
    "            sys.stdout.write(\"episode: {}, loss: {}, reward: {} \\n\".format(episode, av_episode_loss, np.round(av_episode_reward, decimals=2)))\n",
    "            break\n",
    "            \n",
    "    losses.append(av_episode_loss)\n",
    "    rewards.append(episode_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc039f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
